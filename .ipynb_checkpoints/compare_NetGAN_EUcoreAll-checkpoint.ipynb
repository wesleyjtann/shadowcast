{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wesleyjtann/miniconda3/envs/eggen/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from eggen.eggen_saved import *\n",
    "from eggen import utils\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import time\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data chunk size:  25571\n",
      "642\n",
      "Got rid of 642 useless emails! That's 2.51% of the total number of messages in this dataset.\n"
     ]
    }
   ],
   "source": [
    "## Load data\n",
    "# \"\"\" Entire set of email data \"\"\"\n",
    "data = pd.read_csv('./data/EU-core-join.csv')\n",
    "print(\"Data chunk size: \" ,len(data))\n",
    "\n",
    "#### Dept data (conditions)\n",
    "cond_list = pd.read_csv('./data/raw/email-Eu-core-department-labels.txt', sep=\" \", header=None)\n",
    "cond_list.columns = ['ID', 'DEPT']\n",
    "cond_list = cond_list.values\n",
    "\n",
    "def no_selfloop(df, x):\n",
    "    \"\"\"Drops rows containing messages without some specified value in the expected locations. \n",
    "    Returns original dataframe without these values. Don't forget to reindex after doing this!!!\"\"\"\n",
    "    rows = []\n",
    "    for ind in range(x):\n",
    "        if (df.iloc[ind]['SENDER'] == df.iloc[ind]['RECEIVER']):\n",
    "            rows.append(ind)\n",
    "    \n",
    "    print(len(rows))\n",
    "    df = df.drop(df.index[rows])\n",
    "    return df\n",
    "\n",
    "#### Clean data\n",
    "x = len(data.index)\n",
    "data = no_selfloop(data, x)\n",
    "data = data.reset_index()\n",
    "print(\"Got rid of {} useless emails! That's {}% of the total number of messages in this dataset.\".format(x - len(data.index), np.round(((x - len(data.index)) / x) * 100, decimals=2)))\n",
    "\n",
    "x = len(data.index)\n",
    "\n",
    "\n",
    "# ############################ All departments ############################\n",
    "data_small = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_condlist:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41]), array([ 49,  62,  10,  12, 107,  18,  28,  49,  19,  31,  39,  29,   3,\n",
      "        26,  91,  54,  24,  34,   1,  29,  13,  56,  25,  27,   6,   6,\n",
      "         9,  10,   8,   5,   4,   8,   9,   1,  12,  13,  22,  15,  13,\n",
      "         3,   4,   2]))\n",
      "Number of nodes in G:  986\n",
      "Number of edges in G:  16064\n",
      "Number of selfloops in G:  0\n",
      "Selecting 1 largest connected components\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "\n",
    "import networkx as nx\n",
    "import nxviz as nv\n",
    "\n",
    "G = nx.from_pandas_edgelist(data_small, 'SENDER', 'RECEIVER') #, edge_attr=['SENDER DEPT']) # , 'RECEIVER DEPT'\n",
    "\n",
    "\"\"\" Get the subset of cond_list before reindexing from 0 \"\"\"\n",
    "all_nodes = np.arange(1005)\n",
    "train_nodes = np.array(G.nodes) #(348,)\n",
    "nontrain_nodes = np.setdiff1d(all_nodes, train_nodes) #(657,)\n",
    "nontrain = nontrain_nodes.tolist()\n",
    "\n",
    "subset_condlist = np.delete(cond_list, nontrain, 0)\n",
    "\n",
    "# reindexing the condlist subset\n",
    "subset_condlist[:,0] = np.arange(subset_condlist.shape[0])\n",
    "dept_list = np.unique(cond_list[:,1])\n",
    "for i in np.arange(len(dept_list)):\n",
    "    subset_condlist[:,1][subset_condlist[:,1]==dept_list[i]] = i\n",
    "\n",
    "print(\"subset_condlist: \", np.unique(subset_condlist[:,1], return_counts=True))\n",
    "\n",
    "# Relabel nodes indices in G to match the generated indicies\n",
    "G = nx.convert_node_labels_to_integers(G)\n",
    "\n",
    "print(\"Number of nodes in G: \" ,G.number_of_nodes())\n",
    "print(\"Number of edges in G: \" ,G.number_of_edges())\n",
    "print(\"Number of selfloops in G: \" ,G.number_of_selfloops())\n",
    "\n",
    "## Preparing data\n",
    "Adjtraining = nx.adjacency_matrix(G)\n",
    "Adjtraining = sp.csr_matrix(Adjtraining, dtype='float64')\n",
    "_A_obs = Adjtraining\n",
    "_A_obs = _A_obs + _A_obs.T # (597, 597)\n",
    "_A_obs[_A_obs > 1] = 1 # Max value of 1 (597, 597)\n",
    "\n",
    "\"\"\" Reduce input graph to a subgraph where only the nodes in largest n_components are kept. \"\"\" \n",
    "lcc = utils.largest_connected_components(_A_obs) # len(lcc) = 584\n",
    "_A_obs = _A_obs[lcc,:][:,lcc] # (584, 584)\n",
    "_N = _A_obs.shape[0] # 584\n",
    "\n",
    "#### Separate the edges into train, test, validation\n",
    "val_share = 0.1\n",
    "test_share = 0.05\n",
    "seed = 2020 #481516234  \n",
    "\"\"\"\n",
    "Split the edges of the adjacency matrix into train, validation and test edges and randomly samples equal amount of validation and test non-edges. \n",
    "\"\"\"\n",
    "train_ones, val_ones, val_zeros, test_ones, test_zeros = utils.train_val_test_split_adjacency(_A_obs, val_share, test_share, seed, undirected=True, connected=True, asserts=False) \n",
    "\n",
    "## EGGen\n",
    "train_graph = sp.coo_matrix((np.ones(len(train_ones)),(train_ones[:,0], train_ones[:,1]))).tocsr()\n",
    "assert (train_graph.toarray() == train_graph.toarray().T).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Parameters\n",
    "\"\"\" Adjustable parameters for training. \"\"\" \n",
    "# setting GPU id \n",
    "gpu_id = 0\n",
    "# setting the number of nodes\n",
    "_N = _A_obs.shape[0]\n",
    "# setting the length of random walks\n",
    "rw_len = 16 #5 \n",
    "# setting the training data batch size\n",
    "batch_size = 128\n",
    "# getting the number of departments\n",
    "# n_conds=np.unique(data[['SENDER DEPT', 'RECEIVER DEPT']].values).shape[0] #42\n",
    "n_conds=np.unique(data_small[['SENDER DEPT', 'RECEIVER DEPT']].values).shape[0] #5\n",
    "# sample_batch=5000\n",
    "\n",
    "\n",
    "walker = utils.RandomWalker(train_graph, subset_condlist, rw_len, p=1, q=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create our generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate:  Tensor(\"Generator/Generator.int_1/Tanh:0\", shape=(128, 40), dtype=float32)\n",
      "h:  Tensor(\"Generator/Generator.h_1/Tanh:0\", shape=(128, 40), dtype=float32)\n",
      "c:  Tensor(\"Generator/Generator.c_1/Tanh:0\", shape=(128, 40), dtype=float32)\n",
      "Generator initial_states:  1\n",
      "Generator state:  [(<tf.Tensor 'Generator/Generator.c_1/Tanh:0' shape=(128, 40) dtype=float32>, <tf.Tensor 'Generator/Generator.h_1/Tanh:0' shape=(128, 40) dtype=float32>)]\n",
      "Generator inputs:  Tensor(\"Generator/zeros:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator/cell_0/cell_0/basic_lstm_cell/mul_2:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/add_1:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/mul_2:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator/add:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator/add_4:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator/MatMul_1:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator/cell_0/cell_0/basic_lstm_cell/mul_5:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/add_3:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/mul_5:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator/add_5:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator/add_9:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator/MatMul_3:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator/cell_0/cell_0/basic_lstm_cell/mul_8:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/add_5:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/mul_8:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator/add_10:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator/add_14:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator/MatMul_5:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator/cell_0/cell_0/basic_lstm_cell/mul_11:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/add_7:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/mul_11:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator/add_15:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator/add_19:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator/MatMul_7:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator/cell_0/cell_0/basic_lstm_cell/mul_14:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/add_9:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/mul_14:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator/add_20:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator/add_24:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator/MatMul_9:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator/cell_0/cell_0/basic_lstm_cell/mul_17:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/add_11:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/mul_17:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator/add_25:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator/add_29:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator/MatMul_11:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator/cell_0/cell_0/basic_lstm_cell/mul_20:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/add_13:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/mul_20:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator/add_30:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator/add_34:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator/MatMul_13:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator/cell_0/cell_0/basic_lstm_cell/mul_23:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/add_15:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/mul_23:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator/add_35:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator/add_39:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator/MatMul_15:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator/cell_0/cell_0/basic_lstm_cell/mul_26:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/add_17:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/mul_26:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator/add_40:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator/add_44:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator/MatMul_17:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator/cell_0/cell_0/basic_lstm_cell/mul_29:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/add_19:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/mul_29:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator/add_45:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator/add_49:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator/MatMul_19:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator/cell_0/cell_0/basic_lstm_cell/mul_32:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/add_21:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/mul_32:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator/add_50:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator/add_54:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator/MatMul_21:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator/cell_0/cell_0/basic_lstm_cell/mul_35:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/add_23:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/mul_35:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator/add_55:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator/add_59:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator/MatMul_23:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator/cell_0/cell_0/basic_lstm_cell/mul_38:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/add_25:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/mul_38:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator/add_60:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator/add_64:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator/MatMul_25:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator/cell_0/cell_0/basic_lstm_cell/mul_41:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/add_27:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/mul_41:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator/add_65:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator/add_69:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator/MatMul_27:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator/cell_0/cell_0/basic_lstm_cell/mul_44:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/add_29:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/mul_44:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator/add_70:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator/add_74:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator/MatMul_29:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator/cell_0/cell_0/basic_lstm_cell/mul_47:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/add_31:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator/cell_0/cell_0/basic_lstm_cell/mul_47:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator/add_75:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator/add_79:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator/MatMul_31:0\", shape=(128, 128), dtype=float32)\n",
      "intermediate:  Tensor(\"Generator_1/Generator.int_1/Tanh:0\", shape=(128, 40), dtype=float32)\n",
      "h:  Tensor(\"Generator_1/Generator.h_1/Tanh:0\", shape=(128, 40), dtype=float32)\n",
      "c:  Tensor(\"Generator_1/Generator.c_1/Tanh:0\", shape=(128, 40), dtype=float32)\n",
      "Generator initial_states:  1\n",
      "Generator state:  [(<tf.Tensor 'Generator_1/Generator.c_1/Tanh:0' shape=(128, 40) dtype=float32>, <tf.Tensor 'Generator_1/Generator.h_1/Tanh:0' shape=(128, 40) dtype=float32>)]\n",
      "Generator inputs:  Tensor(\"Generator_1/zeros:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_1/cell_0/cell_0/basic_lstm_cell/mul_2:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/add_1:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/mul_2:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_1/add:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_1/add_4:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_1/MatMul_1:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_1/cell_0/cell_0/basic_lstm_cell/mul_5:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/add_3:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/mul_5:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_1/add_5:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_1/add_9:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_1/MatMul_3:0\", shape=(128, 128), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM output:  Tensor(\"Generator_1/cell_0/cell_0/basic_lstm_cell/mul_8:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/add_5:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/mul_8:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_1/add_10:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_1/add_14:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_1/MatMul_5:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_1/cell_0/cell_0/basic_lstm_cell/mul_11:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/add_7:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/mul_11:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_1/add_15:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_1/add_19:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_1/MatMul_7:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_1/cell_0/cell_0/basic_lstm_cell/mul_14:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/add_9:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/mul_14:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_1/add_20:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_1/add_24:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_1/MatMul_9:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_1/cell_0/cell_0/basic_lstm_cell/mul_17:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/add_11:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/mul_17:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_1/add_25:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_1/add_29:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_1/MatMul_11:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_1/cell_0/cell_0/basic_lstm_cell/mul_20:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/add_13:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/mul_20:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_1/add_30:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_1/add_34:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_1/MatMul_13:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_1/cell_0/cell_0/basic_lstm_cell/mul_23:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/add_15:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/mul_23:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_1/add_35:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_1/add_39:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_1/MatMul_15:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_1/cell_0/cell_0/basic_lstm_cell/mul_26:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/add_17:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/mul_26:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_1/add_40:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_1/add_44:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_1/MatMul_17:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_1/cell_0/cell_0/basic_lstm_cell/mul_29:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/add_19:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/mul_29:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_1/add_45:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_1/add_49:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_1/MatMul_19:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_1/cell_0/cell_0/basic_lstm_cell/mul_32:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/add_21:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/mul_32:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_1/add_50:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_1/add_54:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_1/MatMul_21:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_1/cell_0/cell_0/basic_lstm_cell/mul_35:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/add_23:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/mul_35:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_1/add_55:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_1/add_59:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_1/MatMul_23:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_1/cell_0/cell_0/basic_lstm_cell/mul_38:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/add_25:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/mul_38:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_1/add_60:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_1/add_64:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_1/MatMul_25:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_1/cell_0/cell_0/basic_lstm_cell/mul_41:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/add_27:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/mul_41:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_1/add_65:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_1/add_69:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_1/MatMul_27:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_1/cell_0/cell_0/basic_lstm_cell/mul_44:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/add_29:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/mul_44:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_1/add_70:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_1/add_74:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_1/MatMul_29:0\", shape=(128, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_1/cell_0/cell_0/basic_lstm_cell/mul_47:0\", shape=(128, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/add_31:0' shape=(128, 40) dtype=float32>, h=<tf.Tensor 'Generator_1/cell_0/cell_0/basic_lstm_cell/mul_47:0' shape=(128, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_1/add_75:0\", shape=(128, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_1/add_79:0\", shape=(128, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_1/MatMul_31:0\", shape=(128, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Modified keepdims to tf.reduce_max(y, 1, keep_dims=True) in eggen/eggen.py\n",
    "eggen = EGGen(_N, rw_len, walk_generator=walker.walk, gpu_id=gpu_id, use_gumbel=True, disc_iters=3,\n",
    "                W_down_discriminator_size=128, W_down_generator_size=128,\n",
    "                l2_penalty_generator=1e-7, l2_penalty_discriminator=5e-5,\n",
    "                generator_layers=[40], discriminator_layers=[30], temp_start=5, learning_rate=0.0003,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from snapshots/model_best_15.ckpt\n"
     ]
    }
   ],
   "source": [
    "uncond_saver = tf.train.Saver()\n",
    "# uncond_saver.restore(eggen.session, \"snapshots/model_best_33.ckpt\")\n",
    "uncond_saver.restore(eggen.session, \"snapshots/model_best_15.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate random walks on the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intermediate:  Tensor(\"Generator_2/Generator.int_1/Tanh:0\", shape=(10000, 40), dtype=float32)\n",
      "h:  Tensor(\"Generator_2/Generator.h_1/Tanh:0\", shape=(10000, 40), dtype=float32)\n",
      "c:  Tensor(\"Generator_2/Generator.c_1/Tanh:0\", shape=(10000, 40), dtype=float32)\n",
      "Generator initial_states:  1\n",
      "Generator state:  [(<tf.Tensor 'Generator_2/Generator.c_1/Tanh:0' shape=(10000, 40) dtype=float32>, <tf.Tensor 'Generator_2/Generator.h_1/Tanh:0' shape=(10000, 40) dtype=float32>)]\n",
      "Generator inputs:  Tensor(\"Generator_2/zeros:0\", shape=(10000, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_2/cell_0/cell_0/basic_lstm_cell/mul_2:0\", shape=(10000, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/add_1:0' shape=(10000, 40) dtype=float32>, h=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/mul_2:0' shape=(10000, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_2/add:0\", shape=(10000, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_2/add_4:0\", shape=(10000, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_2/MatMul_1:0\", shape=(10000, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_2/cell_0/cell_0/basic_lstm_cell/mul_5:0\", shape=(10000, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/add_3:0' shape=(10000, 40) dtype=float32>, h=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/mul_5:0' shape=(10000, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_2/add_5:0\", shape=(10000, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_2/add_9:0\", shape=(10000, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_2/MatMul_3:0\", shape=(10000, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_2/cell_0/cell_0/basic_lstm_cell/mul_8:0\", shape=(10000, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/add_5:0' shape=(10000, 40) dtype=float32>, h=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/mul_8:0' shape=(10000, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_2/add_10:0\", shape=(10000, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_2/add_14:0\", shape=(10000, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_2/MatMul_5:0\", shape=(10000, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_2/cell_0/cell_0/basic_lstm_cell/mul_11:0\", shape=(10000, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/add_7:0' shape=(10000, 40) dtype=float32>, h=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/mul_11:0' shape=(10000, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_2/add_15:0\", shape=(10000, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_2/add_19:0\", shape=(10000, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_2/MatMul_7:0\", shape=(10000, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_2/cell_0/cell_0/basic_lstm_cell/mul_14:0\", shape=(10000, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/add_9:0' shape=(10000, 40) dtype=float32>, h=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/mul_14:0' shape=(10000, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_2/add_20:0\", shape=(10000, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_2/add_24:0\", shape=(10000, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_2/MatMul_9:0\", shape=(10000, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_2/cell_0/cell_0/basic_lstm_cell/mul_17:0\", shape=(10000, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/add_11:0' shape=(10000, 40) dtype=float32>, h=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/mul_17:0' shape=(10000, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_2/add_25:0\", shape=(10000, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_2/add_29:0\", shape=(10000, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_2/MatMul_11:0\", shape=(10000, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_2/cell_0/cell_0/basic_lstm_cell/mul_20:0\", shape=(10000, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/add_13:0' shape=(10000, 40) dtype=float32>, h=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/mul_20:0' shape=(10000, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_2/add_30:0\", shape=(10000, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_2/add_34:0\", shape=(10000, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_2/MatMul_13:0\", shape=(10000, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_2/cell_0/cell_0/basic_lstm_cell/mul_23:0\", shape=(10000, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/add_15:0' shape=(10000, 40) dtype=float32>, h=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/mul_23:0' shape=(10000, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_2/add_35:0\", shape=(10000, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_2/add_39:0\", shape=(10000, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_2/MatMul_15:0\", shape=(10000, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_2/cell_0/cell_0/basic_lstm_cell/mul_26:0\", shape=(10000, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/add_17:0' shape=(10000, 40) dtype=float32>, h=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/mul_26:0' shape=(10000, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_2/add_40:0\", shape=(10000, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_2/add_44:0\", shape=(10000, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_2/MatMul_17:0\", shape=(10000, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_2/cell_0/cell_0/basic_lstm_cell/mul_29:0\", shape=(10000, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/add_19:0' shape=(10000, 40) dtype=float32>, h=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/mul_29:0' shape=(10000, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_2/add_45:0\", shape=(10000, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_2/add_49:0\", shape=(10000, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_2/MatMul_19:0\", shape=(10000, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_2/cell_0/cell_0/basic_lstm_cell/mul_32:0\", shape=(10000, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/add_21:0' shape=(10000, 40) dtype=float32>, h=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/mul_32:0' shape=(10000, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_2/add_50:0\", shape=(10000, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_2/add_54:0\", shape=(10000, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_2/MatMul_21:0\", shape=(10000, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_2/cell_0/cell_0/basic_lstm_cell/mul_35:0\", shape=(10000, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/add_23:0' shape=(10000, 40) dtype=float32>, h=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/mul_35:0' shape=(10000, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_2/add_55:0\", shape=(10000, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_2/add_59:0\", shape=(10000, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_2/MatMul_23:0\", shape=(10000, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_2/cell_0/cell_0/basic_lstm_cell/mul_38:0\", shape=(10000, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/add_25:0' shape=(10000, 40) dtype=float32>, h=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/mul_38:0' shape=(10000, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_2/add_60:0\", shape=(10000, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_2/add_64:0\", shape=(10000, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_2/MatMul_25:0\", shape=(10000, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_2/cell_0/cell_0/basic_lstm_cell/mul_41:0\", shape=(10000, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/add_27:0' shape=(10000, 40) dtype=float32>, h=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/mul_41:0' shape=(10000, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_2/add_65:0\", shape=(10000, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_2/add_69:0\", shape=(10000, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_2/MatMul_27:0\", shape=(10000, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_2/cell_0/cell_0/basic_lstm_cell/mul_44:0\", shape=(10000, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/add_29:0' shape=(10000, 40) dtype=float32>, h=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/mul_44:0' shape=(10000, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_2/add_70:0\", shape=(10000, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_2/add_74:0\", shape=(10000, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_2/MatMul_29:0\", shape=(10000, 128), dtype=float32)\n",
      "LSTM output:  Tensor(\"Generator_2/cell_0/cell_0/basic_lstm_cell/mul_47:0\", shape=(10000, 40), dtype=float32)\n",
      "LSTM state:  (LSTMStateTuple(c=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/add_31:0' shape=(10000, 40) dtype=float32>, h=<tf.Tensor 'Generator_2/cell_0/cell_0/basic_lstm_cell/mul_47:0' shape=(10000, 40) dtype=float32>),)\n",
      "output_bef:  Tensor(\"Generator_2/add_75:0\", shape=(10000, 986), dtype=float32)\n",
      "softmax output:  Tensor(\"Generator_2/add_79:0\", shape=(10000, 986), dtype=float32)\n",
      "size-reduced inputs:  Tensor(\"Generator_2/MatMul_31:0\", shape=(10000, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sample_many = eggen.generate_discrete(10000, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[269, 584, 269, ..., 142, 689,  14],\n",
       "       [114,  38,  40, ...,  31, 601, 515],\n",
       "       [772,  13, 607, ..., 499, 695, 493],\n",
       "       ...,\n",
       "       [247,  41, 121, ..., 126,   6, 648],\n",
       "       [723, 530, 568, ..., 145,  86, 141],\n",
       "       [287,  86, 178, ..., 647,  82, 170]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_many.eval({eggen.tau: 0.5})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# one-hot matrix of departments for train node ids\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# one hot encode\n",
    "encoded = to_categorical(cond_list[:,1])\n",
    "print(encoded.shape)\n",
    "\n",
    "all_nodes = np.arange(1005) # List of all node ids\n",
    "train_nodes = np.array(G.nodes) # nodes ids that were used in training the model\n",
    "nontrain_nodes = np.setdiff1d(all_nodes, train_nodes) #(all node ids) \\ (train node ids)\n",
    "nontrain = nontrain_nodes.tolist()\n",
    "\n",
    "encoded = np.delete(encoded, nontrain, 0)\n",
    "print(\"train encoded shape: \", encoded.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "samples = []\n",
    "\n",
    "for _ in range(6000): #00): #0):\n",
    "    if (_+1) % 500 == 0:\n",
    "        print(_+1)\n",
    "    samples.append(sample_many.eval({eggen.tau: 0.5}))\n",
    "    \n",
    "rws = np.array(samples).reshape([-1, rw_len])\n",
    "print(\"rws: \", rws.shape)\n",
    "\n",
    "scores_matrix = utils.score_matrix_from_random_walks(rws, _N).tocsr()\n",
    "A_select = sp.csr_matrix((np.ones(len(train_ones)), (train_ones[:,0], train_ones[:,1])))\n",
    "A_select = train_graph\n",
    "print(A_select.sum())\n",
    "\n",
    "sampled_graph = utils.graph_from_scores(scores_matrix, A_select.sum())\n",
    "plt.spy(sampled_graph, markersize=.2)\n",
    "plt.show()\n",
    "\n",
    "utils.edge_overlap(A_select.toarray(), sampled_graph)/A_select.sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "utils.compute_graph_statistics(sampled_graph) #, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/wesleyjtann/miniconda3/envs/eggen/lib/python3.6/site-packages/ipykernel_launcher.py:30: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Retrieving node condition attr to get community statistics \"\"\"\n",
    "G_tmp = nx.from_pandas_edgelist(data_small, 'SENDER', 'RECEIVER') #, edge_attr=['SENDER DEPT']) # , 'RECEIVER DEPT'\n",
    "\n",
    "# Iterate over df rows and set the source and target nodes' attributes for each row:\n",
    "for _, row in data_small.iterrows():       \n",
    "    G_tmp.nodes[row['SENDER']]['attr'] = row['SENDER DEPT']\n",
    "    G_tmp.nodes[row['RECEIVER']]['attr'] = row['RECEIVER DEPT']\n",
    "    \n",
    "eval_condlist = list(nx.get_node_attributes(G_tmp,'attr').values())\n",
    "\n",
    "# one-hot matrix of departments for train node ids\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "values = np.array(eval_condlist)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "# print(integer_encoded)\n",
    "\n",
    "# one hot encode\n",
    "encoded = to_categorical(integer_encoded) #cond_list[:,1])\n",
    "# print(encoded.shape)\n",
    "\n",
    "all_nodes = np.arange(1005) # List of all node ids\n",
    "train_nodes = np.array(G.nodes) # nodes ids that were used in training the model\n",
    "nontrain_nodes = np.setdiff1d(all_nodes, train_nodes) #(all node ids) \\ (train node ids)\n",
    "nontrain = nontrain_nodes.tolist()\n",
    "\n",
    "encoded = np.delete(encoded, nontrain, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:  0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wesleyjtann/miniconda3/envs/eggen/lib/python3.6/site-packages/powerlaw.py:700: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (Theoretical_CDF * (1 - Theoretical_CDF))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:  1\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wesleyjtann/miniconda3/envs/eggen/lib/python3.6/site-packages/powerlaw.py:700: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (Theoretical_CDF * (1 - Theoretical_CDF))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:  2\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wesleyjtann/miniconda3/envs/eggen/lib/python3.6/site-packages/powerlaw.py:700: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (Theoretical_CDF * (1 - Theoretical_CDF))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:  3\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wesleyjtann/miniconda3/envs/eggen/lib/python3.6/site-packages/powerlaw.py:700: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (Theoretical_CDF * (1 - Theoretical_CDF))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial:  4\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wesleyjtann/miniconda3/envs/eggen/lib/python3.6/site-packages/powerlaw.py:700: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (Theoretical_CDF * (1 - Theoretical_CDF))\n"
     ]
    }
   ],
   "source": [
    "dmax,dmin,deg,lcc,wc,cc,tc,sc,law,gini,rel,assrt,coe,ncomp,intra,inter,cpl,eo = ([] for i in range(18))\n",
    "num_trials = 5 #2 #1 #\n",
    "num_paths = 1000 #6000\n",
    "\n",
    "def compute_stats(samples):\n",
    "    rws = np.array(samples).reshape([-1, rw_len])\n",
    "    scores_matrix = utils.score_matrix_from_random_walks(rws, _N).tocsr()\n",
    "    \n",
    "    A_select = sp.csr_matrix((np.ones(len(train_ones)), (train_ones[:,0], train_ones[:,1])))\n",
    "    A_select = train_graph\n",
    "    sampled_graph = utils.graph_from_scores(scores_matrix, A_select.sum())\n",
    "    EO = utils.edge_overlap(A_select.toarray(), sampled_graph)/A_select.sum()\n",
    "    \n",
    "    stats = utils.compute_graph_statistics(sampled_graph) #, encoded)\n",
    "    return stats, EO\n",
    "\n",
    "for trials in range(num_trials):\n",
    "    print(\"trial: \", trials)\n",
    "    samples = []\n",
    "    for _ in range(num_paths): #10): #\n",
    "        if (_+1) % round(num_paths/5) == 0:\n",
    "            print(_+1)\n",
    "        samples.append(sample_many.eval({eggen.tau: 0.5}))\n",
    "        \n",
    "    stats, EO = compute_stats(samples)\n",
    "    \n",
    "    dmax.append(stats['d_max'])\n",
    "    dmin.append(stats['d_min'])\n",
    "    deg.append(stats['d'])\n",
    "    lcc.append(stats['LCC'])\n",
    "    wc.append(stats['wedge_count'])\n",
    "    cc.append(stats['claw_count'])\n",
    "    tc.append(stats['triangle_count'])\n",
    "    sc.append(stats['square_count'])\n",
    "    law.append(stats['power_law_exp'])\n",
    "    gini.append(stats['gini'])\n",
    "    rel.append(stats['rel_edge_distr_entropy'])\n",
    "    assrt.append(stats['assortativity'])\n",
    "    coe.append(stats['clustering_coefficient'])\n",
    "    ncomp.append(stats['n_components'])\n",
    "#     intra.append(stats['intra_community_density'])\n",
    "#     inter.append(stats['inter_community_density'])\n",
    "    cpl.append(stats['cpl'])\n",
    "    eo.append(EO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_stats:  [-0.061118106897072554, 0.004925651524263908, 2.5514972045180757, 0.5022828757430451, 273.2, 1.359997364315166, 0.30830525853229823, 1.0, 27.69574036511156, 986.0, 774728.4, 23604610.2, 38726.8, 41246.8, 0.9368882596583876, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# all_stats = [dmax, dmin, deg, lcc, wc, cc, tc, sc, law, gini, rel, assrt, coe, ncomp, cpl, eo]\n",
    "# ====== ASST CLUST CPL GINI MD PLE EO ====== \n",
    "all_stats = [assrt, coe, cpl, gini, dmax, law, eo, dmin, deg, lcc, wc, cc, tc, sc, rel, ncomp]\n",
    "\n",
    "# avg_stats = [np.mean(dmax), np.mean(dmin), np.mean(deg), np.mean(lcc), np.mean(wc), np.mean(cc), np.mean(tc), np.mean(sc), np.mean(law), np.mean(gini), np.mean(rel), np.mean(assrt), np.mean(coe), np.mean(ncomp), np.mean(cpl), np.mean(eo)]\n",
    "avg_stats = [np.mean(assrt), np.mean(coe), np.mean(cpl), np.mean(gini), np.mean(dmax), np.mean(law), np.mean(eo), np.mean(dmin), np.mean(deg), np.mean(lcc), np.mean(wc), np.mean(cc), np.mean(tc), np.mean(sc), np.mean(rel), np.mean(ncomp)]\n",
    "print(\"avg_stats: \", avg_stats)\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "# stderror_stats = [stats.sem(dmax), stats.sem(dmin), stats.sem(deg), stats.sem(lcc), stats.sem(wc), stats.sem(cc), stats.sem(tc), stats.sem(sc), stats.sem(law), stats.sem(gini), stats.sem(rel), stats.sem(assrt), stats.sem(coe), stats.sem(ncomp), stats.sem(cpl), stats.sem(eo)]\n",
    "stderror_stats = [stats.sem(assrt), stats.sem(coe), stats.sem(cpl), stats.sem(gini), stats.sem(dmax), stats.sem(law), stats.sem(eo), stats.sem(dmin), stats.sem(deg), stats.sem(lcc), stats.sem(wc), stats.sem(cc), stats.sem(tc), stats.sem(sc), stats.sem(rel), stats.sem(ncomp)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "avg_stats = [np.mean(dmax), np.mean(dmin), np.mean(deg), np.mean(lcc), np.mean(wc), np.mean(cc), np.mean(tc), np.mean(sc), np.mean(law), np.mean(gini), np.mean(rel), np.mean(assrt), np.mean(coe), np.mean(ncomp), np.mean(cpl), np.mean(eo)]\n",
    "\n",
    "avg_stats"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from scipy import stats\n",
    "\n",
    "stderror_stats = [stats.sem(dmax), stats.sem(dmin), stats.sem(deg), stats.sem(lcc), stats.sem(wc), stats.sem(cc), stats.sem(tc), stats.sem(sc), stats.sem(law), stats.sem(gini), stats.sem(rel), stats.sem(assrt), stats.sem(coe), stats.sem(ncomp), stats.sem(cpl), stats.sem(eo)]\n",
    "\n",
    "stderror_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"./generate_stats\" #\"./snapshots_gencond\"  #\"./snapshots_gencond2\" \n",
    "log_num = 0\n",
    "data_name  = \"NetGAN_EUcore-top\" #\"EUcore\" #\n",
    "\n",
    "save_stats = \"{}/{}_stats{}.txt\".format(save_directory, data_name, log_num)\n",
    "\n",
    "np.savetxt(save_stats, np.c_[avg_stats,stderror_stats, all_stats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wesleyjtann/miniconda3/envs/eggen/lib/python3.6/site-packages/powerlaw.py:700: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (Theoretical_CDF * (1 - Theoretical_CDF))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'d_max': 285.0,\n",
       " 'd_min': 1.0,\n",
       " 'd': 27.69574036511156,\n",
       " 'LCC': 986,\n",
       " 'wedge_count': 846822.0,\n",
       " 'claw_count': 28308535.0,\n",
       " 'triangle_count': 63226,\n",
       " 'square_count': 151542,\n",
       " 'power_law_exp': 1.3790943393384585,\n",
       " 'gini': 0.5384692862815612,\n",
       " 'rel_edge_distr_entropy': 0.92655643321839,\n",
       " 'assortativity': -0.024215720231687856,\n",
       " 'clustering_coefficient': 0.006700382057919988,\n",
       " 'n_components': 1,\n",
       " 'cpl': 2.654223082546514}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_select = sp.csr_matrix((np.ones(len(train_ones)), (train_ones[:,0], train_ones[:,1])))\n",
    "A_select = train_graph\n",
    "utils.compute_graph_statistics(A_select.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eggen",
   "language": "python",
   "name": "eggen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
